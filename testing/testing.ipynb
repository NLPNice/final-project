{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "580a2652-8eb4-4ab4-9c86-2a6f6ae631bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Dxgcl0g0iUw",
    "outputId": "9844d40f-7c5a-49ad-ac42-a9e6379bcb6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb 21 14:41:02 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   47C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "045d4ac6-b7a5-4dca-a9a3-06e5c5da1087",
   "metadata": {
    "id": "Gy6_XE7M2hOo"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets torchinfo rouge_score git+https://github.com/google-research/bleurt.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0d41981-9cea-4f79-ab4e-6da74e56d41c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0y3R2Y9djqYA",
    "outputId": "96a9824b-845e-4383-e8b3-b0cdb1d760d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive not mounted, so nothing to flush and unmount.\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.flush_and_unmount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59481c37-6984-4434-b17e-5e46ec73dc78",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SiKi_g-93-nG",
    "outputId": "0ff88440-7a58-45cb-eb72-dc8b21c97243"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5abec24-acc7-45fd-a9d7-e1edd2044333",
   "metadata": {
    "id": "kUyFtE2WbINv"
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a42d1c9-cda7-4d2b-8461-2f52c5c32b41",
   "metadata": {},
   "source": [
    "# Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0184c82a-8b59-4147-976a-5a94b1e8f314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load already tokenized dataset\n",
    "from datasets import load_dataset, load_from_disk\n",
    "DATASET_PATH = \"/gdrive/MyDrive/university/tokenized_dataset\"\n",
    "dataset = load_from_disk(GDRIVE_DATASET_PATH)\n",
    "\n",
    "# split dataset\n",
    "train_test = dataset.train_test_split(test_size=0.15, seed=RANDOM_SEED)\n",
    "test_valid = train_test[\"train\"].train_test_split(test_size=0.1, seed=RANDOM_SEED)\n",
    "train_test[\"train\"] = test_valid[\"train\"]\n",
    "train_test[\"valid\"] = test_valid[\"test\"]\n",
    "dataset = train_test\n",
    "\n",
    "# delete from memory unused values\n",
    "del train_test\n",
    "del test_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca27760-f6d1-4753-99a4-5957fce5a2c9",
   "metadata": {},
   "source": [
    "# Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1ce6cf-6474-4c6e-ac6d-afbb1a042995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BigBirdPegasusForConditionalGeneration\n",
    "from torchinfo import summary\n",
    "\n",
    "MODEL_PATH = \"google/bigbird-pegasus-large-bigpatent\"\n",
    "\n",
    "model = BigBirdPegasusForConditionalGeneration.from_pretrained(\n",
    "    \"google/bigbird-pegasus-large-bigpatent\",\n",
    "    block_size=16,\n",
    "    num_random_blocks=3,\n",
    "    attention_type=\"block_sparse\",\n",
    "    use_cache=False) # required for fp16\n",
    "model.gradient_checkpointing_enable()\n",
    "summary(model, dtypes=[\"torch.IntTensor\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d5e1f8-6c38-40ae-8c8e-a9bcc67a258f",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110e1819-817e-430c-8c31-b2d62bf3b1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/bigbird-pegasus-large-bigpatent\")\n",
    "valid_sample = dataset[\"valid\"][\"input_ids\"][0]\n",
    "\n",
    "# print summary\n",
    "tokenizer.decode(valid_sample, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2cf04d-381b-40b0-9fda-13da204f9554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print claim\n",
    "tokenizer.decode(dataset[\"valid\"][\"decoder_input_ids\"][0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184a5383-28da-4c19-8825-845ca826f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "valid_sample = torch.tensor(valid_sample)\n",
    "inputs = tokenizer([tokenizer.decode(valid_sample, skip_special_tokens=True)], \n",
    "                   max_length=2048, \n",
    "                   return_tensors=\"pt\", \n",
    "                   truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b852e39-d7c8-403b-b955-96b8b2723680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set return_num_sequences > 1\n",
    "beam_outputs = model.generate(\n",
    "    inputs[\"input_ids\"], \n",
    "    max_length=50, \n",
    "    num_beams=5, \n",
    "    #no_repeat_ngram_size=2,\n",
    "    repetition_penalty=0.5,\n",
    "    #num_return_sequences=5, \n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "# now we have 3 output sequences\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "for i, beam_output in enumerate(beam_outputs):\n",
    "  print(\"{}: {}\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
